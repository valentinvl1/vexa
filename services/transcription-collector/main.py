import uvicorn
from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Query, HTTPException, Depends, Header
import logging
import asyncio
from datetime import datetime, timezone
import redis
import redis.asyncio as aioredis
from sqlalchemy.ext.asyncio import AsyncSession
from typing import Optional

from shared_models.database import get_db, init_db
from shared_models.models import Meeting
from filters import TranscriptionFilter
from config import (
    REDIS_URL,
    REDIS_STREAM_NAME,
    REDIS_CONSUMER_GROUP,
    REDIS_STREAM_READ_COUNT,
    REDIS_STREAM_BLOCK_MS,
    CONSUMER_NAME,
    PENDING_MSG_TIMEOUT_MS,
    BACKGROUND_TASK_INTERVAL,
    IMMUTABILITY_THRESHOLD,
    LOG_LEVEL,
    REDIS_SPEAKER_EVENTS_STREAM_NAME,
    REDIS_SPEAKER_EVENTS_CONSUMER_GROUP
)
from api.endpoints import router as api_router
from streaming.consumer import claim_stale_messages, consume_redis_stream, consume_speaker_events_stream
from background.db_writer import process_redis_to_postgres

app = FastAPI(
    title="Transcription Collector",
    description="Collects and stores transcriptions from WhisperLive instances via Redis Streams."
)
app.include_router(api_router)

# Configure logging
logging.basicConfig(
    level=LOG_LEVEL,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger("transcription_collector")

# Redis connection
redis_client: Optional[aioredis.Redis] = None

# Initialize transcription filter
transcription_filter = TranscriptionFilter()

# Background task references
redis_to_pg_task = None
stream_consumer_task = None
speaker_stream_consumer_task = None

@app.on_event("startup")
async def startup():
    global redis_client, redis_to_pg_task, stream_consumer_task, speaker_stream_consumer_task, transcription_filter
    
    logger.info(f"Connecting to Redis at {REDIS_URL}")
    temp_redis_client = aioredis.from_url(REDIS_URL, decode_responses=True)
    await temp_redis_client.ping()
    redis_client = temp_redis_client
    app.state.redis_client = redis_client
    logger.info("Redis connection successful.")
    
    try:
        logger.info(f"Ensuring Redis Stream group '{REDIS_CONSUMER_GROUP}' exists for stream '{REDIS_STREAM_NAME}'...")
        await redis_client.xgroup_create(
            name=REDIS_STREAM_NAME, 
            groupname=REDIS_CONSUMER_GROUP, 
            id='0',
            mkstream=True
        )
        logger.info(f"Consumer group '{REDIS_CONSUMER_GROUP}' ensured for stream '{REDIS_STREAM_NAME}'.")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP Consumer Group name already exists" in str(e):
            logger.info(f"Consumer group '{REDIS_CONSUMER_GROUP}' already exists for stream '{REDIS_STREAM_NAME}'.")
        else:
            logger.error(f"Failed to create Redis consumer group: {e}", exc_info=True)
            return
    
    # Ensure speaker events stream and consumer group exist
    try:
        logger.info(f"Ensuring Redis Stream group '{REDIS_SPEAKER_EVENTS_CONSUMER_GROUP}' exists for stream '{REDIS_SPEAKER_EVENTS_STREAM_NAME}'...")
        await redis_client.xgroup_create(
            name=REDIS_SPEAKER_EVENTS_STREAM_NAME, 
            groupname=REDIS_SPEAKER_EVENTS_CONSUMER_GROUP, 
            id='0',
            mkstream=True
        )
        logger.info(f"Consumer group '{REDIS_SPEAKER_EVENTS_CONSUMER_GROUP}' ensured for stream '{REDIS_SPEAKER_EVENTS_STREAM_NAME}'.")
    except redis.exceptions.ResponseError as e:
        if "BUSYGROUP Consumer Group name already exists" in str(e):
            logger.info(f"Consumer group '{REDIS_SPEAKER_EVENTS_CONSUMER_GROUP}' already exists for stream '{REDIS_SPEAKER_EVENTS_STREAM_NAME}'.")
        else:
            logger.error(f"Failed to create Redis consumer group for speaker events: {e}", exc_info=True)
            return
    
    logger.info("Database initialized.")
    
    await claim_stale_messages(redis_client)
    
    redis_to_pg_task = asyncio.create_task(process_redis_to_postgres(redis_client, transcription_filter))
    logger.info(f"Redis-to-PostgreSQL task started (Interval: {BACKGROUND_TASK_INTERVAL}s, Threshold: {IMMUTABILITY_THRESHOLD}s)")
    
    stream_consumer_task = asyncio.create_task(consume_redis_stream(redis_client))
    logger.info(f"Redis Stream consumer task started (Stream: {REDIS_STREAM_NAME}, Group: {REDIS_CONSUMER_GROUP}, Consumer: {CONSUMER_NAME})")

    speaker_stream_consumer_task = asyncio.create_task(consume_speaker_events_stream(redis_client))
    logger.info(f"Speaker Events Redis Stream consumer task started (Stream: {REDIS_SPEAKER_EVENTS_STREAM_NAME}, Group: {REDIS_SPEAKER_EVENTS_CONSUMER_GROUP}, Consumer: {CONSUMER_NAME + '-speaker'})")

@app.on_event("shutdown")
async def shutdown():
    logger.info("Application shutting down...")
    tasks_to_cancel = [redis_to_pg_task, stream_consumer_task, speaker_stream_consumer_task]
    for i, task in enumerate(tasks_to_cancel):
        if task and not task.done():
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                logger.info(f"Background task {i+1} cancelled.")
            except Exception as e:
                logger.error(f"Error during background task {i+1} cancellation: {e}", exc_info=True)
    
    if redis_client:
        await redis_client.close()
        logger.info("Redis connection closed.")
    
    logger.info("Shutdown complete.")

if __name__ == "__main__":
    # Removed uvicorn runner, rely on Docker CMD
    pass
